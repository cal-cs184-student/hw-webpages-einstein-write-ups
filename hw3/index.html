<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Tamnhi Vu and Samuel German </div>

		<br>

		<div style = "text-align: center"> Link to webpage: 
			<br> <a href="https://cal-cs184-student.github.io/hw-webpages-einstein-write-ups/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-einstein-write-ups/hw3/index.html</a> </div>
		<div style = "text-align: center"> Link to GitHub repository: 
			<br> <a href="https://github.com/cal-cs184-student/sp25-hw3-einstein3">https://github.com/cal-cs184-student/sp25-hw3-einstein3</a> </div>
		
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>I'm late, I'm late, for a very important date! </figcaption>
			<figcaption>- White Rabbit from Alice in the Wonderland</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this project, we displayed how images are being displayed depending on how the rays hit the scene. By utilizing important formulas,
		we are able to see where the rays intersect and use barycentric weights to get normal color shading. We then implement Bounding Volume
		Hierarchy to speed up rendering of complex images, those that have a lot of geometrical complexities. We can do this by correctly choosing
		the splitting point so that we are recursing at little as possible. We then implemented direct and global illuminance to showcase how we can replicate
		how images rendered on our computer can reflect light like how it does in the real world. Lastly, we implement adaptive sampling to avoid problems using 
		a high fixed bumber of samples per pixel. 

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		Our first step in the rendering pipeline is ray generation. This process allows us to generate the camera rays, used to determine what hits the scene, 
		from the start of the camera's position and pass through a point on the image plane. We went from image spave to sensor in camera space and we were able
		to outpit a ray in the world space. We transformed the coordinates to camera space, generate the ray in the camera space, which we were able to finally 
		transform it into  the world space. We used ray generation by converting the field of view, normalizing the sample coordinates, transforming the
		ray to the world space, and finally setting up the array by initializing our starting position and direction. We lastly define our valid range for
		intersesctions for nClip and fClip. We were able to loop through the number of sample camera rays to trace them in order to average out the vector by using
		Monte Carlo estimator to do random sampling to estimate the pixel radiance and to make images appear more realistic by simulating how light interacts with objects.
		For our primitive intersection we are looking for intersections with objects in the scene itself where we can check if and where a ray hits an object by using the
		ray equation r(t) = o + td.

		<p>For our triangle intersection algorithm, we implemented it using the Moller-Trumbore algorithm to see if the ray intersects
			with a triangle which solves it using barycentric coordinates. We were able to use the equation by computing the edges, 
			taking the cross product which is perpendicuar to one of the edges and ray direction. By using the dot product we can solve 
			for the intersection parameters by doing using the barycentric coordinates. Finally, we can update our intersection information
			by getting the new closest intersection by interpolating the normal with barycentric weights. 
		</p>

		<div style = "text-align: center"> <b> <u> Normal shading for small .dae files: </u> </b> </div>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Part1/cube.png" width="400px"/>
				  <figcaption><b>Cube</b></figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Part1/cow.png" width="400px"/>
				  <figcaption><b>Cow</b></figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Part1/CBempty.png" width="400px"/>
				  <figcaption><b>Empty Box</b></figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Part1/CBspheres.png" width="400px"/>
				  <figcaption><b>Box with Spheres</b></figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		The BVH construction algorithm is a recursive algorithm that partitions the scene's primitives into bounding boxes to 
		speed up the ray intersection tests. We first compute the bounding box, decide which axis to split on, partition the 
		primitives, and recurse. We choose the splitting heuristic by choosing the longest axis of the bounding box which allows more of an even
		distribution. Due to the fact that we split this way, we have a balanced tree will overall lead to fewer recursive 
		tests. 

		<p>

		<div style = "text-align: center"> <b> <u> Normal shading for large .dae files: </u> </b> </div> 
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="Part2/blob.png" width="400px"/>
				  <figcaption><b>Blob</b></figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Part2/wall-e.png" width="400px"/>
				  <figcaption><b>Wall-E</b></figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="Part2/CBlucy.png" width="400px"/>
				  <figcaption><b>Lucy</b></figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="Part2/maxplanck.png" width="400px"/>
				  <figcaption><b>Maxplanck</b></figcaption>
				</td>
			  </tr>
			</table>
		</div>
		

		<p>After rendering images with and without BVH acceleration, we can see that having the BVH acceleration drastcially speeds
			up the process to render the image. Lucy was able to render in less than a second with BVH acceleration while without BVH
			acceleration, it took about 18 minutes to run due to the inefficient partitioning and unnecessary extra recurseive calls. 
			Though the cow is not as complex, we can see that it took about 3 minutes with my implementation before the BVH acceleration, 
			but ended up being less than one second after the BVH acceleration. 
			Instead of having it be a well-balanced bushy tree, without BVH acceleration, it is more like a left leaning skinny tree. 
			we tested this on the different images like the blob and wall-e, which all run under 1 second. Even though these have 
			different geometrical complexities, BVH is able to upper bound the rendering time to be less than a second regardless of
			how long it took to render before BVH acceleration.</p>

		<h2>Part 3: Direct Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		
		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>